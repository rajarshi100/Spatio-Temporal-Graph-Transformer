import numpy as np
import pandas as pd
import os

# Input the prediction Interval and look-back window and output the dataset
class DataLoader:
    def __init__(self, data_path, look_back_window, prediction_interval):
        # base_dd = os.getcwd() + '/Data/' + str(dataset_name) + '.h5'
        base_dd = data_path #os.getcwd() + '/pems-bay.h5'    #'/V_228.csv'
        self.lb = int(look_back_window)
        self.pi = int(prediction_interval)
        #df = pd.read_hdf(base_dd)
        #df.replace(0,df.mean(axis=0),inplace=True)
        #self.data = df.values

        df = pd.read_csv(base_dd)
        self.data = df.values
        # data_array = df.values
        # self.data = data_array/np.max(data_array)

    def make_dataset(self):
        # Convert the data_list element into dataset using prediction interval and look-back window info
        total_samples = self.data.shape[0] - self.lb - self.pi + 1
        sample_dim = self.data.shape[1]

        # Create the dataset
        dataset_x = np.zeros((total_samples, self.lb, sample_dim))
        dataset_y = np.zeros((total_samples, self.pi, sample_dim))

        for j in range(total_samples):
            dataset_x[j, :, :] = self.data[j:(j+self.lb), :]
            dataset_y[j, :, :] = self.data[(j+self.lb):(j+self.lb+self.pi), :]

        return dataset_x, dataset_y

    def generate_dataset(self):
        return self.make_dataset()


from google.colab import drive
drive.mount('/content/drive')


data_path = '/content/drive/MyDrive/pems-bay.h5'
data_path_2 = '/content/drive/MyDrive/PeMSD7(M)_dataset/V_228.csv'
adj_mat_path_d2 = '/content/drive/MyDrive/PeMSD7(M)_dataset/W_228.csv'

# Load Dataset
dl = DataLoader(data_path_2, 12, 9)
data = dl.generate_dataset()
X = data[0]
Y = data[1]

X = np.expand_dims(X, axis=3)

# Randomly re-shuffling the data and ground truths
np.random.seed(2)
reorder = np.random.permutation(X.shape[0])
X = X[reorder, :, :, :]
Y = Y[reorder, :, :]

# Dividing data into training, validation and test sets
net_data_size = int(X.shape[0])
train_size = int(np.ceil(0.7 * net_data_size))
val_size = int(np.ceil(0.15 * net_data_size))
test_size = net_data_size - train_size - val_size

X_tr = X[0:train_size, :, :, :]
Y_tr = Y[0:train_size, 0, :]
X_val = X[train_size:(train_size + val_size), :, :, :]
Y_val = Y[train_size:(train_size + val_size), 0, :]
X_test = X[(train_size + val_size):, :, :, :]
Y_test = Y[(train_size + val_size):, :, :]

print(X_tr.shape)
print(X_val.shape)
print(X_test.shape)

# Perform data normalization (use train set mean and variance)
X_mean = np.mean(X_tr, axis=0)
X_var = np.sqrt(np.sum(np.square(np.subtract(X_tr, X_mean)), axis=0) / X_tr.shape[0])
X_tr = np.divide(np.subtract(X_tr, X_mean), X_var)
X_var = np.where(X_var>0, X_var, 1)
X_val = np.divide(np.subtract(X_val, X_mean), X_var)
X_test = np.divide(np.subtract(X_test, X_mean), X_var)

X_tr = np.squeeze(X_tr)
X_val = np.squeeze(X_val)
X_test = np.squeeze(X_test)


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers


# Transformer Block implemented as a Layer
class TransformerBlock(layers.Layer):
    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):
        super(TransformerBlock, self).__init__()
        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.ffn = keras.Sequential(
            [layers.Dense(ff_dim, activation="relu"), layers.Dense(embed_dim),]
        )
        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)
        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)
        self.dropout1 = layers.Dropout(rate)
        self.dropout2 = layers.Dropout(rate)

    def call(self, inputs, training):
        attn_output = self.att(inputs, inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)


class PositionEmbeddingLayer(layers.Layer):
    def __init__(self, sequence_length, output_dim, **kwargs):
        super(PositionEmbeddingLayer, self).__init__(**kwargs)
        self.position_embedding_layer = layers.Embedding(
            input_dim=(sequence_length), output_dim=output_dim
        )
        self.sequence_length = sequence_length

    def call(self, inputs):
        position_indices = tf.range(self.sequence_length)  #tf.range(1, self.sequence_length + 1, 1)
        embedded_words = inputs
        embedded_indices = self.position_embedding_layer(position_indices)
        return embedded_words + embedded_indices


class PositionEmbeddingLayerC(layers.Layer):
    def __init__(self, sequence_length, output_dim, **kwargs):
        super(PositionEmbeddingLayerC, self).__init__(**kwargs)
        self.position_embedding_layer = layers.Embedding(
            input_dim=(sequence_length), output_dim=3
        )
        self.sequence_length = sequence_length

    def call(self, inputs):
        position_indices = tf.range(self.sequence_length)  #tf.range(1, self.sequence_length + 1, 1)
        embedded_words = inputs
        embedded_indices = self.position_embedding_layer(position_indices)
        inp_shp = tf.shape(inputs)
        alias = tf.zeros(shape=(inp_shp[0], inp_shp[1], 3))
        embedded_indices_up = alias + embedded_indices
        return tf.concat((inputs, embedded_indices_up), 2)


class PositionEmbeddingFixedWeights(layers.Layer):
    def __init__(self, sequence_length, output_dim, **kwargs):
        super(PositionEmbeddingFixedWeights, self).__init__(**kwargs)
        position_embedding_matrix = self.get_position_encoding((sequence_length+1), output_dim)
        self.position_embedding_layer = layers.Embedding(
            input_dim=(sequence_length+1), output_dim=output_dim,
            weights=[position_embedding_matrix],
            trainable=False
        )
        self.sequence_length = sequence_length

    def get_position_encoding(self, seq_len, d, n=10000):
        P = np.zeros((seq_len, d))
        for k in range(seq_len):
            for i in np.arange(int(d/2)):
                denominator = np.power(n, 2*i/d)
                P[k, 2*i] = np.sin(k/denominator)
                P[k, 2*i+1] = np.cos(k/denominator)
        return P


    def call(self, inputs):
        position_indices = tf.range(1, self.sequence_length + 1, 1)
        embedded_words = inputs
        embedded_indices = self.position_embedding_layer(position_indices)
        return embedded_words + embedded_indices


# Creating the model (position embedding layer)
num_road_seg = X_tr.shape[2]

#Ks = 3
n = num_road_seg

num_attn_heads = 3
hidden_layer_dim = 64  # Hidden layer size in feed forward network inside transformer

# Initializing the transformer blocks
num_transformer_blocks = 4
transformer_blocks = []

for i in range(num_transformer_blocks):
    transformer_blocks.append(TransformerBlock(num_road_seg, num_attn_heads, hidden_layer_dim))

# Model
inputs = layers.Input(shape=(X_tr.shape[1], X_tr.shape[2],))
x = inputs

# Trainable Embedding
embedding_layer = PositionEmbeddingLayer(12, num_road_seg)
x = embedding_layer(x)

# Fized Embedding
#fixed_embedding_layer = PositionEmbeddingFixedWeights(12, num_road_seg)
#x = fixed_embedding_layer(x)

for i in range(num_transformer_blocks):
    x = transformer_blocks[i](x)

x = layers.GlobalAveragePooling1D()(x)
x = layers.Dropout(0.2)(x)
x = layers.Dense(256, activation="relu")(x)
x = layers.Dropout(0.2)(x)
outputs = layers.Dense(X_tr.shape[2])(x)

model = keras.Model(inputs=inputs, outputs=outputs)

model.summary()


# Learning Rate Scheduler
def scheduler(epoch, lr):
    exp = np.floor((1 + epoch) / 60)
    alpha = 0.0008 * (0.6 ** exp)
    return float(alpha)

# setup callbacks
callbacks = [tf.keras.callbacks.LearningRateScheduler(scheduler)]

model.compile(optimizer="RMSprop", loss="mse", metrics=["mse","mae"])
history = model.fit(
    X_tr, Y_tr, batch_size=64, epochs=500, validation_data=(X_val, Y_val), callbacks=callbacks
)


# Unroll before calculating testing MAPE (for pred intervals [1, 2, 3, 6, 9])
# Predict upto 45mins
mape_list = []
mae_list = []
rmse_list = []
pred_int_list = [int(0), int(1), int(2), int(5), int(8)]

X_test = np.expand_dims(X_test, axis=3)
X_test_copy = X_test    # Keep copy to restore original value after this run
for un_l in range(9):
    # For every testing sample we must predict the output at each time step and compute mape for pred_int_list steps

    # Make predictions for the next step
    y_pred_nxt = model.predict(np.squeeze(X_test), verbose=0)

    # Compute mape for predicton intervals in pred_int_list
    if un_l in pred_int_list:
        ground_truth = Y_test[:, un_l, :]
        test_mape = 100 * np.mean(abs(y_pred_nxt - ground_truth) / (abs(ground_truth)+0.01))
        test_mae = np.mean(abs(y_pred_nxt - ground_truth))
        test_se = np.sqrt(np.mean(np.square(y_pred_nxt - ground_truth)))
        mape_list.append(test_mape)
        mae_list.append(test_mae)
        rmse_list.append(test_se)

    # Update the testing data: delete the speeds of the first time step and insert predicted value at the end
    # Undo the normalization
    X_test = np.add(np.multiply(X_test, X_var), X_mean)

    # Update the test data
    X_test = np.concatenate((X_test[:, 1:, :, :], np.expand_dims(y_pred_nxt, axis=[1, 3])), axis=1)

    # Reapply normalization
    X_test = np.divide(np.subtract(X_test, X_mean), X_var)

# Display Testing Results
print('\n')
for pr_id in range(len(pred_int_list)):
    print('Test MAPE values (%) for prediction interval ' + str(5*(pred_int_list[pr_id]+1)) + 'min:')
    print(mape_list[pr_id])

    print('\n')

    print('Test MAE values for prediction interval ' + str(5 * (pred_int_list[pr_id] + 1)) + 'min:')
    print(mae_list[pr_id])

    print('\n')

    print('Test RMSE values for prediction interval ' + str(5 * (pred_int_list[pr_id] + 1)) + 'min:')
    print(rmse_list[pr_id])

    print('\n')


